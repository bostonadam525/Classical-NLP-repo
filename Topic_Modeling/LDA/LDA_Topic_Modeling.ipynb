{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LDA Topic Modeling\n",
        "* Notebook by Adam Lang\n",
        "* Date: 8/5/2024\n",
        "\n",
        "# Overview\n",
        "* In this notebook I will go over implementing LDA topic modeling algorithm from scratch using sklearn in python.\n",
        "\n",
        "## Notes\n",
        "* First we will import LDA from sklearn.\n",
        "* For feature extraction we will use `CountVectorizer`. However, you can use `TfidfVectorizer` as well.\n",
        "   * The `CountVectorizer` will simply count each word in the document."
      ],
      "metadata": {
        "id": "TjWPJvy0XQn1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CCSo_qnlXKiZ"
      },
      "outputs": [],
      "source": [
        "## imports\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import numpy as np\n",
        "\n",
        "# instantiate a CountVectorizer() object\n",
        "cvectorizer = CountVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Create a test corpus\n",
        "corpus = [\"I love cooking\", \"I have prepared a cake today\", \"He is going to a new place\", \"He will learn cooking there\"]"
      ],
      "metadata": {
        "id": "zY6oyeBYXnVx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit_transform the corpus with count vectorizer\n",
        "cvz = cvectorizer.fit_transform(corpus)"
      ],
      "metadata": {
        "id": "-ex-cj7-YB9q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## lets see the output\n",
        "cvz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUCDAnAFYI7N",
        "outputId": "bc6f70df-91d8-4b7d-8427-4b6dcc133420"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<4x15 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 17 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary:\n",
        "* We now have a sparse matrix 4 rows x 15 columns.\n",
        "* The matrix represents the unique elements in our corpus."
      ],
      "metadata": {
        "id": "oDoUMYUiY24L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## we now create a vocabulary array to represent the corpus\n",
        "vocab = cvectorizer.get_feature_names_out()\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBnWzRykYLfH",
        "outputId": "b2964b7b-9092-48e6-f4e8-922e5dda5751"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['cake', 'cooking', 'going', 'have', 'he', 'is', 'learn', 'love',\n",
              "       'new', 'place', 'prepared', 'there', 'to', 'today', 'will'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the LDA topic model\n",
        "* `n_components` is number of topics we want to extract.\n",
        "* `max_iter` is max number of iterations the LDA algorithm should run through before reaching steady state.\n",
        "* `random_state` is well known, we use this so we can replicate our results."
      ],
      "metadata": {
        "id": "c9mFnMd2ZY-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## LDA model instantiate\n",
        "lda_model = LatentDirichletAllocation(n_components = 3, max_iter = 20, random_state=20)\n",
        "\n",
        "# Fit LDA model on data\n",
        "X_topics = lda_model.fit_transform(cvz)\n",
        "\n",
        "# get topic components\n",
        "topic_words = lda_model.components_"
      ],
      "metadata": {
        "id": "16qESnEhZSiv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## print first index of topics\n",
        "topic_words[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aasK_yKFZ65l",
        "outputId": "28f3f264-004b-4a73-ad27-d7cad6ecb389"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.33409872, 1.3520179 , 0.33426983, 0.33409872, 0.3344864 ,\n",
              "       0.33426983, 0.33484162, 1.33184251, 0.33426983, 0.33426983,\n",
              "       0.33409872, 0.33484162, 0.33426983, 0.33409872, 0.33484162])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extracting topic words\n",
        "* We can extract a specific number of words per topic."
      ],
      "metadata": {
        "id": "NZjtGu9hxuIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_top_words = 4\n",
        "\n",
        "for i, topic_dist in enumerate(topic_words):\n",
        "    sorted_topic_dist = np.argsort(topic_dist)\n",
        "    topic_words = np.array(vocab)[sorted_topic_dist]\n",
        "    topic_words = topic_words[:-n_top_words:-1]\n",
        "    print (\"Topic\", str(i+1), topic_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rn--1zLgZ-BX",
        "outputId": "e93f8eb2-058a-4782-d3d8-1d81a0cf72de"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 1 ['cooking' 'love' 'will']\n",
            "Topic 2 ['today' 'prepared' 'have']\n",
            "Topic 3 ['he' 'to' 'place']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extracting Topics by Document"
      ],
      "metadata": {
        "id": "RTZQ-GzF1ELj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LDA model transform using count vectorizer -- assign to doc_topic\n",
        "doc_topic = lda_model.transform(cvz)\n",
        "\n",
        "#iterate over all documents\n",
        "for n in range(doc_topic.shape[0]):\n",
        "  topic_doc = doc_topic[n].argmax() #obtain max probability\n",
        "  print(\"Document\", n+1, \" --- Topic:\", topic_doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIs42uWhyyyj",
        "outputId": "b89ea372-6ae9-4d3c-d3ff-53511a31a2f1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document 1  --- Topic: 0\n",
            "Document 2  --- Topic: 1\n",
            "Document 3  --- Topic: 2\n",
            "Document 4  --- Topic: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "\n",
        "**Pros of LDA**\n",
        "- Able to handle large datasets and can be easily parallelized\n",
        "- Can assign a probability to a new document due to the document-topic Dirichlet distribution\n",
        "- Topics are open to human interpretation\n",
        "\n",
        "**Cons of LDA**\n",
        "- Extremely computationally expensive\n",
        "- Usually may not work well for short documents and text files\n",
        "- The number of topics must be known/set beforehand\n",
        "- The bag-of-words approach disregards the semantic representation of words in a corpus, similar to LSA and pLSA\n",
        "- An estimation of Bayes parameters lies under the assumption of exchangeability for the documents used\n",
        "- LDA requires an extensive pre-processing phase to obtain a significant representation from the textual input data\n",
        "- Some studies report LDA topic modeling may yield too general (Rizvi et al., 2019) or irrelevant (Alnusyan et al., 2020) topics.\n",
        "   * Results may also be inconsistent across different executions (Egger et al., 2021).\n",
        "\n",
        "\n",
        "In summary, we were able to implement LDA topic modeling which is a classical statistical topic modeling technique. However, with newer SOTA models such as BERTopic which use transformers, there are more viable options that consider semantic context and are less prone to error."
      ],
      "metadata": {
        "id": "S2wzxCho2Wa5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O7QcbWrM1wxd"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}